{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('venv-luo': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "6f5bb23da6bd6ab87296804a7ae062a565b497c650c7064ca78191dd29b49fd6"
   }
  },
  "interpreter": {
   "hash": "6f5bb23da6bd6ab87296804a7ae062a565b497c650c7064ca78191dd29b49fd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import config\n",
    "sys.path.append(config.root)\n",
    "import glob\n",
    "import torch\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import threading as td\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader.read_preprocess import read_preprocess\n",
    "from dataloader.parallel_loader import threads_read, threads_scene_dset\n",
    "from dataloader.loader import scene_tensor_dset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------Data paths-------------- #\n",
    "paths_as = sorted(glob.glob(config.root+'/data/s1_ascend/*'))\n",
    "paths_des = sorted(glob.glob(config.root+'/data/s1_descend/*'))\n",
    "paths_truth = sorted(glob.glob(config.root+'/data/s1_truth/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "### -----data read & pre-processing------- ###\n",
    "scene_list, truth_list = read_preprocess(paths_as=paths_as,\\\n",
    "                                    paths_des=paths_des, paths_truth=paths_truth)\n",
    "len(scene_list)\n"
   ]
  },
  {
   "source": [
    "### Single-threading loading\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "## ------- single thread ------- \n",
    "tra_dset_single = scene_tensor_dset(scene_tensor_list=scene_list, \\\n",
    "                truth_tensor_list=truth_list, transforms=config.transforms_tra, scales=[2048,512,256])\n",
    "print(tra_dset_single.__len__())\n",
    "tra_loader_single = torch.utils.data.DataLoader(tra_dset_single, \\\n",
    "                                        batch_size=4, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Multi-threading loading\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "threads_tra_dset = threads_scene_dset(scene_list[0:15], \\\n",
    "                                    truth_list[0:15], num_thread=10)\n",
    "\n",
    "print(threads_tra_dset.__len__())\n",
    "threads_tra_loader = torch.utils.data.DataLoader(threads_tra_dset, \\\n",
    "                                        batch_size=4, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "source": [
    "### Comparison"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1\n",
      "time/patch:0.006246183713277181,dset size: 150\n",
      "epoch 2\n",
      "time/patch:0.006181867917378744,dset size: 150\n",
      "epoch 3\n",
      "time/patch:0.0064342244466145835,dset size: 150\n",
      "epoch 4\n",
      "time/patch:0.005789198875427246,dset size: 150\n",
      "epoch 5\n",
      "time/patch:0.005553585688273112,dset size: 150\n",
      "epoch 6\n",
      "time/patch:0.006084349950154623,dset size: 150\n",
      "epoch 7\n",
      "time/patch:0.006383938789367676,dset size: 150\n",
      "epoch 8\n",
      "time/patch:0.0065955845514933265,dset size: 150\n",
      "epoch 9\n",
      "time/patch:0.005766787528991699,dset size: 150\n",
      "epoch 10\n",
      "time/patch:0.006104575792948405,dset size: 150\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print(f'epoch {epoch+1}')\n",
    "    num = 0\n",
    "    start = time.time()\n",
    "    # for patch, truth in tra_loader_single:\n",
    "    for patch, truth in threads_tra_loader:\n",
    "        num += truth.shape[0]\n",
    "        # print(num)\n",
    "    print(f'time/patch:{(time.time()-start)/num},dset size: {num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time/patch:0.004549534320831299\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "patch_lists, ptruth_lists = threads_read(scene_list, truth_list, num_thread=20)\n",
    "print(f'time/patch:{(time.time()-start)/len(patch_lists)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time/patch_list:0.004754376411437988, dset_size:20\n"
     ]
    }
   ],
   "source": [
    "from dataloader.parallel_loader import scenes2patches, threads_read\n",
    "start = time.time()\n",
    "patch_list, ptruth_list = scenes2patches(scene_list=scene_list, truth_list =truth_list)\n",
    "print(f'time/patch_list:{(time.time()-start)/len(ptruth_list)}, dset_size:{len(ptruth_list)}')\n",
    "\n"
   ]
  }
 ]
}