{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "from notebooks import config\n",
    "import glob\n",
    "from dataloader.read_normalize import read_normalize\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.imgShow import imgShow\n",
    "from dataloader.loader import scene_tensor_dset\n",
    "from dataloader.parallel_loader import threads_scene_dset\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "paths_as = sorted(glob.glob(config.dir_as + '/*'))\n",
    "paths_des = sorted(glob.glob(config.dir_des+'/*'))\n",
    "paths_truth = sorted(glob.glob(config.dir_truth+'/*'))\n",
    "print(paths_as[0])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/yons/Desktop/developer-luo/SWatNet/data/s1_ascend/scene01_s1_ascend.tif\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "### -----data read & pre-processing------- ###\n",
    "scene_list, truth_list = read_normalize(paths_as=paths_as,\\\n",
    "                                    paths_des=paths_des, paths_truth=paths_truth)\n",
    "len(scene_list)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "## ------- single thread ------- \n",
    "tra_dset_single = scene_tensor_dset(scene_tensor_list=scene_list, \\\n",
    "                truth_tensor_list=truth_list, transforms=config.transforms_tra, \\\n",
    "                scales=[2048, 512, 256])\n",
    "print(f'single thread loader: {tra_dset_single.__len__()}')\n",
    "tra_loader_single = torch.utils.data.DataLoader(tra_dset_single, \\\n",
    "                                                batch_size=4, shuffle=True)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "single thread loader: 20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test full data loader\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "## ------ multiple threads ------\n",
    "threads_tra_dset = threads_scene_dset(scene_list[0:15], \\\n",
    "                    truth_list[0:15], transforms=config.transforms_tra, num_thread=20)\n",
    "print(f'multiple theads loader: {threads_tra_dset.__len__()}')\n",
    "threads_tra_loader = torch.utils.data.DataLoader(threads_tra_dset, \\\n",
    "                                        batch_size=4, shuffle=True, num_workers=0)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "multiple theads loader: 300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for epoch in range(5):\n",
    "    print(f'epoch {epoch+1}')\n",
    "    num = 0\n",
    "    start = time.time()\n",
    "    # for patch, truth in tra_loader_single:\n",
    "    for patch, truth in threads_tra_loader:\n",
    "        num += truth.shape[0]\n",
    "        # print(num)\n",
    "    print(f'time/patch:{(time.time()-start)/num},dset size: {num}')\n",
    "    print(f'time/all_patch:{(time.time()-start)}')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1\n",
      "time/patch:0.006274845600128174,dset size: 300\n",
      "time/all_patch:1.8825490474700928\n",
      "epoch 2\n",
      "time/patch:0.0061096437772115075,dset size: 300\n",
      "time/all_patch:1.8329811096191406\n",
      "epoch 3\n",
      "time/patch:0.006022097269694011,dset size: 300\n",
      "time/all_patch:1.8067188262939453\n",
      "epoch 4\n",
      "time/patch:0.006204984982808431,dset size: 300\n",
      "time/all_patch:1.8615899085998535\n",
      "epoch 5\n",
      "time/patch:0.006224339008331299,dset size: 300\n",
      "time/all_patch:1.8673875331878662\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test crop and data augmentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch\n",
    "from utils.preprocess import crop_scales\n",
    "from utils.img_aug import rotate, flip, missing, numpy2tensor, torch_noise\n",
    "\n",
    "def scenes2patches(scene_list, truth_list, scales=[2048, 512, 256]):    \n",
    "    patch_list, ptruth_list = [],[]\n",
    "    transforms = [rotate(prob=0.3), flip(prob=0.3), missing(prob=0.2, ratio_max = 0.2), \\\n",
    "                                numpy2tensor(), torch_noise(prob=0.3, std_min=0.001, std_max=0.1)]\n",
    "     #'''convert image to patches group'''\n",
    "    zip_data = list(zip(scene_list, truth_list))\n",
    "    for scene, truth in zip_data:\n",
    "        start_0 = time.time()\n",
    "        patches_group, truth = crop_scales(scales=scales, threads=False)(scene, truth)\n",
    "        start_1 = time.time()\n",
    "        time_crop = start_1-start_0 \n",
    "        for transform in transforms:\n",
    "            patches_group, truth = transform(patches_group, truth)\n",
    "        time_aug = time.time()-start_1\n",
    "        print(f'time/crop:{time_crop:.3f}, time/aug:{time_aug:.3f}')  \n",
    "\n",
    "        truth = torch.unsqueeze(truth,0)\n",
    "        patch_list.append(patches_group), ptruth_list.append(truth)\n",
    "    return patch_list, ptruth_list\n",
    "    \n",
    "patch_list, ptruth_list = scenes2patches(scene_list, truth_list, scales=[2048, 512, 256])\n",
    "print(len(patch_list))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time/crop:0.006, time/aug:0.002\n",
      "time/crop:0.003, time/aug:0.002\n",
      "time/crop:0.003, time/aug:0.007\n",
      "time/crop:0.003, time/aug:0.001\n",
      "time/crop:0.003, time/aug:0.008\n",
      "time/crop:0.003, time/aug:0.001\n",
      "time/crop:0.003, time/aug:0.006\n",
      "time/crop:0.003, time/aug:0.003\n",
      "time/crop:0.003, time/aug:0.001\n",
      "time/crop:0.003, time/aug:0.001\n",
      "time/crop:0.003, time/aug:0.002\n",
      "time/crop:0.003, time/aug:0.001\n",
      "time/crop:0.003, time/aug:0.001\n",
      "time/crop:0.003, time/aug:0.001\n",
      "time/crop:0.003, time/aug:0.001\n",
      "time/crop:0.003, time/aug:0.007\n",
      "time/crop:0.003, time/aug:0.004\n",
      "time/crop:0.003, time/aug:0.009\n",
      "time/crop:0.003, time/aug:0.007\n",
      "time/crop:0.003, time/aug:0.002\n",
      "20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. test crop/crop_scales"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from utils.preprocess import crop_scales, crop\n",
    "### ----- crop -----\n",
    "for i in range(5):\n",
    "    start = time.time()\n",
    "    patch_high, ptruth_high = crop(scene_list[0], truth_list[0], size=(256, 256))\n",
    "    print(f'time/patch_group:{time.time()-start}')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time/patch_group:2.288818359375e-05\n",
      "time/patch_group:1.1920928955078125e-05\n",
      "time/patch_group:6.67572021484375e-06\n",
      "time/patch_group:6.198883056640625e-06\n",
      "time/patch_group:5.9604644775390625e-06\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "### ----- crop_scales -----\n",
    "for i in range(5):\n",
    "    start = time.time()\n",
    "    patch_group, ptruth = crop_scales(scales=(2048, 512, 256), threads=False)(scene_list[0], truth_list[0])\n",
    "    print(f'---time/patch_group:{time.time()-start:.4f}')\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---time/patch_group:0.0036\n",
      "---time/patch_group:0.0032\n",
      "---time/patch_group:0.0030\n",
      "---time/patch_group:0.0030\n",
      "---time/patch_group:0.0030\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Test downsample"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "patch_high, ptruth_high = crop(scene_list[0], truth_list[0], size=(2048, 2048))\n",
    "patch_mid, ptruth_mid = crop(scene_list[0], truth_list[0], size=(512, 512))\n",
    "patch_low, ptruth_low = crop(scene_list[0], truth_list[0], size=(256, 256))\n",
    "patch_group = [patch_high, patch_mid, patch_low]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "import cv2\n",
    "start = time.time()\n",
    "patch_group_down = []\n",
    "start_0 = time.time()\n",
    "for patch in patch_group[:-1]:\n",
    "    ## per band downsample faster than multi-band downsample\n",
    "    start = time.time()\n",
    "    # patch_down=[cv2.resize(patch[num], dsize=(256, 256), \\\n",
    "                        # interpolation=cv2.INTER_AREA) for num in range(patch.shape[0])]\n",
    "    patch_down=[cv2.resize(patch[num], dsize=(256, 256), \\\n",
    "                    interpolation=cv2.INTER_LINEAR) for num in range(patch.shape[0])]\n",
    "    print(time.time()-start)\n",
    "    patch_group_down.append(np.array(patch_down))\n",
    "patch_group_down.append(patch_group[-1])\n",
    "\n",
    "print(f'time/patches_down_256:{time.time()-start_0}')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0019335746765136719\n",
      "0.0006608963012695312\n",
      "time/patches_down_256:0.003793954849243164\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. test data augmentation\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 test noisy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import random\n",
    "patch_group_down, ptruth=crop_scales(scales=(2048, 512, 256),threads=False)(scene_list[0],truth_list[0])\n",
    "patch_group_down, ptruth = numpy2tensor()(patch_group_down, ptruth)\n",
    "\n",
    "start = time.time()\n",
    "std = random.uniform(0.001, 0.1)\n",
    "for i in range(len(patch_group_down)):\n",
    "    # noises = np.random.normal(loc=0, scale=std, size=patch_group_down[i].shape)\n",
    "    noises = torch.normal(mean=0, std=std, size=(4,256,256))\n",
    "    patch_noisy = patch_group_down[i]+noises\n",
    "\n",
    "print(f'time/add_noisy:{(time.time()-start)}')\n",
    "# imgShow(patch_noisy.numpy().transpose(1,2,0))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time/add_noisy:0.004816532135009766\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 test missing\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import random\n",
    "patch_group_down, ptruth=crop_scales(scales=(2048, 512, 256),threads=False)(scene_list[0],truth_list[0])\n",
    "start = time.time()\n",
    "patch_group_down_miss, ptruth_miss = missing(prob=1)(patch_group_down, ptruth)\n",
    "print(f'time/add_missing:{(time.time()-start)}')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time/add_missing:0.0014522075653076172\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f5bb23da6bd6ab87296804a7ae062a565b497c650c7064ca78191dd29b49fd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('venv-luo': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}