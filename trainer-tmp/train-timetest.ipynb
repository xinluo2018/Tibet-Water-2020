{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from notebooks import config\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from dataloader.loader import patch_tensor_dset\n",
    "from dataloader.parallel_loader import threads_scene_dset\n",
    "from dataloader.preprocess import read_normalize\n",
    "from utils.metric import oa_binary, miou_binary\n",
    "from utils.geotif_io import readTiff\n",
    "from model.seg_model.unet import unet\n",
    "from model.seg_model.deeplabv3_plus import deeplabv3plus, deeplabv3plus_imp\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# ------------device---------------- #\n",
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# ----------Data paths-------------- #\n",
    "# ---s1 path---\n",
    "paths_as = sorted(glob.glob(config.dir_as+'/*'))\n",
    "paths_des = sorted(glob.glob(config.dir_des+'/*'))\n",
    "paths_truth = sorted(glob.glob(config.dir_truth+'/*'))\n",
    "# # ---patch path---\n",
    "# paths_patch_tra = sorted(glob.glob(config.root+'/data/tra_patches/*'))\n",
    "paths_patch_val = sorted(glob.glob(config.dir_patch_val+'/*'))\n",
    "\n",
    "#----------Training parameter------- #\n",
    "epochs = 200\n",
    "lr = 0.005\n",
    "torch.manual_seed(999)   # make the trianing replicable\n",
    "random.seed(999)         # make the data augmentation replicable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "## train dataset\n",
    "scene_list, truth_list = read_normalize(paths_as=paths_as, \\\n",
    "                            paths_des=paths_des, paths_truth=paths_truth)\n",
    "tra_dset = threads_scene_dset(scene_list[0:15], \\\n",
    "                            truth_list[0:15], \\\n",
    "                            transforms=config.transforms_tra, \\\n",
    "                            num_thread=20)\n",
    "## validation dataset\n",
    "patch_list_val = [torch.load(path) for path in paths_patch_val]\n",
    "val_dset = patch_tensor_dset(patch_pair_list=patch_list_val)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(tra_dset.__len__())\n",
    "print(val_dset.__len__())\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300\n",
      "250\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# tra_loader = torch.utils.data.DataLoader(tra_dset, batch_size=8, shuffle=True)\n",
    "tra_loader = torch.utils.data.DataLoader(tra_dset, batch_size=4, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dset, batch_size=4)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "### Configuration\n",
    "# model = unet(num_bands=4, num_classes=2).to(device)\n",
    "model = deeplabv3plus(num_bands=4, num_classes=2).to(device)\n",
    "# model = deeplabv3plus_xception65(img_channels=6, num_classes=2, output_stride=32).to(device)\n",
    "# model = deeplabv3plus_mobilev2_imp(img_channels=6, num_classes=2).to(device)\n",
    "# summary(model, input_size=(6, 512, 512))\n",
    "# loss_ce = nn.CrossEntropyLoss()\n",
    "loss_bce = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "'''------train step------'''\n",
    "def train_step(model, loss_fn, optimizer, x, y):\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, y.float())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    miou = miou_binary(pred=pred, truth=y)\n",
    "    oa = oa_binary(pred=pred, truth=y)\n",
    "    return loss, miou, oa\n",
    "\n",
    "'''------test step------'''\n",
    "def test_step(model, loss_fn, x, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y.float())\n",
    "    miou = miou_binary(pred=pred, truth=y)\n",
    "    oa = oa_binary(pred=pred, truth=y)\n",
    "    return loss, miou, oa\n",
    "\n",
    "'''------train loops------'''\n",
    "def train_loops(model, loss_fn, optimizer, tra_loader, test_loader, epoches, lr_scheduler):\n",
    "    size_tra_loader = len(tra_loader)\n",
    "    size_test_loader = len(test_loader)\n",
    "    for epoch in range(epoches):\n",
    "        # !free -m   # print the memory to be used\n",
    "        start_epoch = time.time()\n",
    "        traload_start = time.time()\n",
    "        tra_loss, test_loss = 0, 0\n",
    "        tra_miou, test_miou = 0, 0\n",
    "        tra_oa, test_oa = 0, 0\n",
    "        '''-----train the model-----'''\n",
    "        time_traload = []\n",
    "        time_testload = []\n",
    "        time_train = []\n",
    "        time_test = []\n",
    "        for x_batch, y_batch in tra_loader:\n",
    "            x_batch, y_batch = [batch.to(device) for batch in x_batch], y_batch.to(device)\n",
    "            x_batch = x_batch[2]    #!!!note: x_batch[2] for single-scale model\n",
    "            batch_loadend = time.time()  # \n",
    "            time_traload.append(batch_loadend-traload_start) # test time\n",
    "            loss, miou, oa = train_step(model=model, loss_fn=loss_fn, \n",
    "                                    optimizer=optimizer, x=x_batch, y=y_batch)\n",
    "            time_train.append(time.time()-batch_loadend)\n",
    "            tra_loss += loss.item()\n",
    "            tra_miou += miou.item()\n",
    "            tra_oa += oa.item()\n",
    "            traload_start = time.time()\n",
    "        lr_scheduler.step()  # dynamic adjust learning rate\n",
    "        '''-----test the model-----'''\n",
    "        testload_start = time.time()\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch, y_batch = [batch.to(device) for batch in x_batch], y_batch.to(device)            \n",
    "            x_batch = x_batch[2]   #!!!note: x_batch[2] for single-scale model\n",
    "            batch_loadend = time.time()  # for test time\n",
    "            time_testload.append(batch_loadend-testload_start) # test time\n",
    "            loss, miou, oa = test_step(model=model, loss_fn=loss_fn, \n",
    "                                                    x=x_batch, y=y_batch)\n",
    "            time_test.append(time.time()-batch_loadend)\n",
    "            test_loss += loss.item()\n",
    "            test_miou += miou.item()\n",
    "            test_oa += oa.item()\n",
    "            testload_start = time.time()\n",
    "\n",
    "        format = 'ep: {}, tradata load: {:.2f}, testdata load: {:.2f}, model train: {:.2f}, model test: {:.2f}, all time: {:.2f}'\n",
    "        print(format.format(epoch, np.sum(time_traload), np.sum(time_testload), np.sum(time_train), np.sum(time_test), time.time()-start_epoch))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_loops(model=model,\n",
    "            loss_fn=loss_bce,\n",
    "            optimizer=optimizer,\n",
    "            tra_loader=tra_loader,\n",
    "            test_loader=val_loader,\n",
    "            epoches=100,\n",
    "            lr_scheduler=lr_scheduler)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep: 0, tradata load: 1.96, testdata load: 0.22, model train: 5.51, model test: 0.86, all time: 8.96\n",
      "ep: 1, tradata load: 1.96, testdata load: 0.20, model train: 4.83, model test: 0.84, all time: 8.25\n",
      "ep: 2, tradata load: 1.98, testdata load: 0.21, model train: 4.83, model test: 0.87, all time: 8.30\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f5bb23da6bd6ab87296804a7ae062a565b497c650c7064ca78191dd29b49fd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('venv-luo': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "6f5bb23da6bd6ab87296804a7ae062a565b497c650c7064ca78191dd29b49fd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}